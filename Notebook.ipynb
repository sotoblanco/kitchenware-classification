{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Create a experimental tracking system with W&B\n\nDetails about the set up [here](https://www.kaggle.com/code/ayuraj/experiment-tracking-with-weights-and-biases)","metadata":{}},{"cell_type":"code","source":"# get the key api from W&B for experimental tracking\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_api\") ","metadata":{"execution":{"iopub.status.busy":"2023-01-16T23:38:35.162213Z","iopub.execute_input":"2023-01-16T23:38:35.162791Z","iopub.status.idle":"2023-01-16T23:38:35.452649Z","shell.execute_reply.started":"2023-01-16T23:38:35.162698Z","shell.execute_reply":"2023-01-16T23:38:35.451807Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom wandb.keras import WandbCallback\nwandb.login(key=wandb_api)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T23:40:02.023707Z","iopub.execute_input":"2023-01-16T23:40:02.024050Z","iopub.status.idle":"2023-01-16T23:40:08.745698Z","shell.execute_reply.started":"2023-01-16T23:40:02.024020Z","shell.execute_reply":"2023-01-16T23:40:08.744659Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import glob\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom tensorflow import keras\n\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.xception import preprocess_input\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom sklearn.model_selection import train_test_split\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-01-16T23:40:14.378419Z","iopub.execute_input":"2023-01-16T23:40:14.379042Z","iopub.status.idle":"2023-01-16T23:40:14.649462Z","shell.execute_reply.started":"2023-01-16T23:40:14.379005Z","shell.execute_reply":"2023-01-16T23:40:14.648469Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_extra = pd.read_csv('../input/kitchenware-extra-images/data.csv')\ndf_extra['filename'] = '../input/kitchenware-extra-images/data/' + df_extra['Id'] + '.jpg'","metadata":{"execution":{"iopub.status.busy":"2023-01-16T23:43:52.600665Z","iopub.execute_input":"2023-01-16T23:43:52.601686Z","iopub.status.idle":"2023-01-16T23:43:52.614306Z","shell.execute_reply.started":"2023-01-16T23:43:52.601615Z","shell.execute_reply":"2023-01-16T23:43:52.613284Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_org = pd.read_csv('../input/kitchenware-classification/train.csv', dtype={'Id': str})\ndf_org['filename'] = '../input/kitchenware-classification/images/' + df_org['Id'] + '.jpg'","metadata":{"execution":{"iopub.status.busy":"2023-01-16T23:45:06.353137Z","iopub.execute_input":"2023-01-16T23:45:06.353565Z","iopub.status.idle":"2023-01-16T23:45:06.377058Z","shell.execute_reply.started":"2023-01-16T23:45:06.353529Z","shell.execute_reply":"2023-01-16T23:45:06.373025Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df, df_extra])","metadata":{"execution":{"iopub.status.busy":"2023-01-16T23:45:09.013720Z","iopub.execute_input":"2023-01-16T23:45:09.014075Z","iopub.status.idle":"2023-01-16T23:45:09.020787Z","shell.execute_reply.started":"2023-01-16T23:45:09.014046Z","shell.execute_reply":"2023-01-16T23:45:09.019565Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Since we want to make sure to have a good validation schema \n# we split the data into training, validation and testing\ndf_full_train, df_test = train_test_split(\n    df, test_size=0.2, random_state=1,\n    stratify=df['label']\n)\n\ndf_train, df_val = train_test_split(\n    df_full_train, test_size=0.25,\n    random_state=1, stratify=df_full_train['label']\n)\n\n# train on df_train, validate in df_val\n# if the results are good test on df_test\n# if the results are good train on df_train and validate on df_test and make a sumbission","metadata":{"execution":{"iopub.status.busy":"2023-01-16T23:45:46.209414Z","iopub.execute_input":"2023-01-16T23:45:46.209791Z","iopub.status.idle":"2023-01-16T23:45:46.235563Z","shell.execute_reply.started":"2023-01-16T23:45:46.209753Z","shell.execute_reply":"2023-01-16T23:45:46.234416Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# set the model architecture\n\ndef make_model(learning_rate, droprate, input_shape, inner_layer):\n    base_model = Xception(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(input_shape, input_shape, 3)\n    )\n    base_model.trainable = False\n\n    inputs = keras.Input(shape=(input_shape, input_shape, 3))\n\n    base = base_model(inputs, training=False)\n    vectors = keras.layers.GlobalAveragePooling2D()(base)\n    dense = keras.layers.Dense(inner_layer, activation='relu')(vectors)\n    dropout = keras.layers.Dropout(droprate)(dense)\n    outputs = keras.layers.Dense(6, activation=\"linear\")(dropout)\n\n    model = keras.Model(inputs, outputs)\n    \n    learning_rate = learning_rate\n    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n\n    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-16T23:45:54.636312Z","iopub.execute_input":"2023-01-16T23:45:54.636673Z","iopub.status.idle":"2023-01-16T23:45:54.645502Z","shell.execute_reply.started":"2023-01-16T23:45:54.636622Z","shell.execute_reply":"2023-01-16T23:45:54.644483Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Configure the parameters for the W&B dashboard","metadata":{}},{"cell_type":"code","source":"# Initialize W&B and specify the project and entity name\nrun = wandb.init(\n        project='kitchenware-classification',name='eight-run-test',\n        config={\n        \"learning_rate\":0.001,\n        \"droprate\": 0.2,\n        \"input_shape\":550,\n        \"inner_layer\": 50,\n        \"epochs\":100,\n        \"batch_size\":32,\n        \"loss_function\":\"crossentropy\",\n        \"architecture\":\"CNN\",\n        \"dataset\":\"Kitchenware-plus-extra\"\n        })\n    \nconfig = wandb.config","metadata":{"execution":{"iopub.status.busy":"2023-01-17T00:06:25.286458Z","iopub.execute_input":"2023-01-17T00:06:25.286841Z","iopub.status.idle":"2023-01-17T00:06:36.905993Z","shell.execute_reply.started":"2023-01-17T00:06:25.286808Z","shell.execute_reply":"2023-01-17T00:06:36.905042Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:fifog3dr) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='80.438 MB of 80.438 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▆▇█▇██</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>loss</td><td>█▃▃▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▂▇▅▁▆▅█▄</td></tr><tr><td>val_loss</td><td>▇▃▁▃▃▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPS</td><td>5.84642</td></tr><tr><td>accuracy</td><td>0.9735</td></tr><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.18657</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>loss</td><td>0.07918</td></tr><tr><td>val_accuracy</td><td>0.93492</td></tr><tr><td>val_loss</td><td>0.21324</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">seventh-run-test</strong>: <a href=\"https://wandb.ai/sotoblanco/kitchenware-classification/runs/fifog3dr\" target=\"_blank\">https://wandb.ai/sotoblanco/kitchenware-classification/runs/fifog3dr</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230116_234622-fifog3dr/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:fifog3dr). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.9 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230117_000625-zszkp0y9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/sotoblanco/kitchenware-classification/runs/zszkp0y9\" target=\"_blank\">eight-run-test</a></strong> to <a href=\"https://wandb.ai/sotoblanco/kitchenware-classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}}]},{"cell_type":"code","source":"# Set up the early stopping callback with a patience of 5 epochs\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T23:46:37.228951Z","iopub.execute_input":"2023-01-16T23:46:37.229468Z","iopub.status.idle":"2023-01-16T23:46:37.238397Z","shell.execute_reply.started":"2023-01-16T23:46:37.229420Z","shell.execute_reply":"2023-01-16T23:46:37.237156Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# data loaders\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    df_train,\n    x_col='filename',\n    y_col='label',\n    target_size=(config.input_shape, config.input_shape),\n    batch_size=config.batch_size,\n)\n\n# data loaders\nval_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\nval_generator = val_datagen.flow_from_dataframe(\n    df_val,\n    x_col='filename',\n    y_col='label',\n    target_size=(config.input_shape, config.input_shape),\n    batch_size=config.batch_size,\n)\n\ntrain_full_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_full_generator = train_full_datagen.flow_from_dataframe(\n    df_full_train,\n    x_col='filename',\n    y_col='label',\n    target_size=(config.input_shape, config.input_shape),\n    batch_size=config.batch_size,\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T00:07:49.388898Z","iopub.execute_input":"2023-01-17T00:07:49.389287Z","iopub.status.idle":"2023-01-17T00:07:52.258874Z","shell.execute_reply.started":"2023-01-17T00:07:49.389252Z","shell.execute_reply":"2023-01-17T00:07:52.257839Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Found 4792 validated image filenames belonging to 6 classes.\nFound 1598 validated image filenames belonging to 6 classes.\nFound 6390 validated image filenames belonging to 6 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint = keras.callbacks.ModelCheckpoint(\n    'kitchenware_v5_{epoch:02d}_{val_accuracy:.3f}.h5',\n    save_best_only=True,\n    monitor='val_accuracy',\n    mode='max'   \n)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T00:08:01.677582Z","iopub.execute_input":"2023-01-17T00:08:01.677947Z","iopub.status.idle":"2023-01-17T00:08:01.683020Z","shell.execute_reply.started":"2023-01-17T00:08:01.677917Z","shell.execute_reply":"2023-01-17T00:08:01.681997Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Add the function to track the results of your model","metadata":{}},{"cell_type":"code","source":"model = make_model(learning_rate=config.learning_rate,droprate=config.droprate,\n                   input_shape=config.input_shape, inner_layer=config.inner_layer)\n\n# add the wandbCallback\nmodel.fit(\n    train_full_generator,\n    epochs=config.epochs,\n    validation_data=val_generator,\n    callbacks=[checkpoint, early_stopping, WandbCallback()]\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T00:08:16.541416Z","iopub.execute_input":"2023-01-17T00:08:16.541796Z","iopub.status.idle":"2023-01-17T03:09:06.774177Z","shell.execute_reply.started":"2023-01-17T00:08:16.541763Z","shell.execute_reply":"2023-01-17T03:09:06.773246Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"2023-01-17 00:08:18.932214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 00:08:18.932618: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n2023-01-17 00:08:18.932810: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n2023-01-17 00:08:18.933428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 00:08:18.933973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 00:08:18.934328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 00:08:18.934896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 00:08:18.935262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-17 00:08:18.935519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2023-01-17 00:08:18.946267: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n  function_optimizer: function_optimizer did nothing. time = 0.008ms.\n  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n200/200 [==============================] - 203s 997ms/step - loss: 0.3813 - accuracy: 0.8975 - val_loss: 0.1578 - val_accuracy: 0.9549\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/100\n200/200 [==============================] - 197s 984ms/step - loss: 0.1627 - accuracy: 0.9521 - val_loss: 0.1251 - val_accuracy: 0.9587\nEpoch 3/100\n200/200 [==============================] - 197s 982ms/step - loss: 0.1277 - accuracy: 0.9618 - val_loss: 0.1107 - val_accuracy: 0.9650\nEpoch 4/100\n200/200 [==============================] - 197s 986ms/step - loss: 0.1064 - accuracy: 0.9654 - val_loss: 0.0917 - val_accuracy: 0.9750\nEpoch 5/100\n200/200 [==============================] - 198s 992ms/step - loss: 0.0967 - accuracy: 0.9698 - val_loss: 0.0887 - val_accuracy: 0.9756\nEpoch 6/100\n200/200 [==============================] - 198s 988ms/step - loss: 0.0844 - accuracy: 0.9743 - val_loss: 0.0731 - val_accuracy: 0.9800\nEpoch 7/100\n200/200 [==============================] - 196s 980ms/step - loss: 0.0764 - accuracy: 0.9767 - val_loss: 0.0722 - val_accuracy: 0.9793\nEpoch 8/100\n200/200 [==============================] - 197s 983ms/step - loss: 0.0667 - accuracy: 0.9808 - val_loss: 0.0609 - val_accuracy: 0.9856\nEpoch 9/100\n200/200 [==============================] - 195s 975ms/step - loss: 0.0604 - accuracy: 0.9815 - val_loss: 0.0557 - val_accuracy: 0.9850\nEpoch 10/100\n200/200 [==============================] - 196s 977ms/step - loss: 0.0539 - accuracy: 0.9831 - val_loss: 0.0483 - val_accuracy: 0.9862\nEpoch 11/100\n200/200 [==============================] - 192s 962ms/step - loss: 0.0510 - accuracy: 0.9845 - val_loss: 0.0454 - val_accuracy: 0.9881\nEpoch 12/100\n200/200 [==============================] - 198s 992ms/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.0476 - val_accuracy: 0.9875\nEpoch 13/100\n200/200 [==============================] - 198s 991ms/step - loss: 0.0443 - accuracy: 0.9883 - val_loss: 0.0397 - val_accuracy: 0.9906\nEpoch 14/100\n200/200 [==============================] - 196s 979ms/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 0.0305 - val_accuracy: 0.9912\nEpoch 15/100\n200/200 [==============================] - 198s 987ms/step - loss: 0.0355 - accuracy: 0.9901 - val_loss: 0.0284 - val_accuracy: 0.9931\nEpoch 16/100\n200/200 [==============================] - 199s 993ms/step - loss: 0.0310 - accuracy: 0.9920 - val_loss: 0.0265 - val_accuracy: 0.9925\nEpoch 17/100\n200/200 [==============================] - 197s 983ms/step - loss: 0.0288 - accuracy: 0.9922 - val_loss: 0.0265 - val_accuracy: 0.9931\nEpoch 18/100\n200/200 [==============================] - 196s 982ms/step - loss: 0.0291 - accuracy: 0.9920 - val_loss: 0.0255 - val_accuracy: 0.9900\nEpoch 19/100\n200/200 [==============================] - 195s 976ms/step - loss: 0.0254 - accuracy: 0.9931 - val_loss: 0.0206 - val_accuracy: 0.9950\nEpoch 20/100\n200/200 [==============================] - 198s 989ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0168 - val_accuracy: 0.9962\nEpoch 21/100\n200/200 [==============================] - 197s 985ms/step - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.0159 - val_accuracy: 0.9962\nEpoch 22/100\n200/200 [==============================] - 197s 985ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 0.0143 - val_accuracy: 0.9969\nEpoch 23/100\n200/200 [==============================] - 199s 994ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.0133 - val_accuracy: 0.9969\nEpoch 24/100\n200/200 [==============================] - 196s 980ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.0132 - val_accuracy: 0.9975\nEpoch 25/100\n200/200 [==============================] - 197s 985ms/step - loss: 0.0150 - accuracy: 0.9972 - val_loss: 0.0098 - val_accuracy: 0.9975\nEpoch 26/100\n200/200 [==============================] - 198s 991ms/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.0096 - val_accuracy: 0.9975\nEpoch 27/100\n200/200 [==============================] - 195s 975ms/step - loss: 0.0142 - accuracy: 0.9967 - val_loss: 0.0084 - val_accuracy: 0.9975\nEpoch 28/100\n200/200 [==============================] - 198s 988ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.0094 - val_accuracy: 0.9975\nEpoch 29/100\n200/200 [==============================] - 198s 990ms/step - loss: 0.0143 - accuracy: 0.9962 - val_loss: 0.0078 - val_accuracy: 0.9981\nEpoch 30/100\n200/200 [==============================] - 197s 985ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0065 - val_accuracy: 0.9975\nEpoch 31/100\n200/200 [==============================] - 197s 982ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0065 - val_accuracy: 0.9981\nEpoch 32/100\n200/200 [==============================] - 198s 988ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.0089 - val_accuracy: 0.9962\nEpoch 33/100\n200/200 [==============================] - 197s 983ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.0060 - val_accuracy: 0.9981\nEpoch 34/100\n200/200 [==============================] - 197s 982ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0049 - val_accuracy: 0.9975\nEpoch 35/100\n200/200 [==============================] - 194s 966ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.0037 - val_accuracy: 0.9981\nEpoch 36/100\n200/200 [==============================] - 197s 983ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0066 - val_accuracy: 0.9962\nEpoch 37/100\n200/200 [==============================] - 197s 985ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.0046 - val_accuracy: 0.9981\nEpoch 38/100\n200/200 [==============================] - 196s 981ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0033 - val_accuracy: 0.9987\nEpoch 39/100\n200/200 [==============================] - 195s 974ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0047 - val_accuracy: 0.9994\nEpoch 40/100\n200/200 [==============================] - 197s 983ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0040 - val_accuracy: 0.9981\nEpoch 41/100\n200/200 [==============================] - 197s 983ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.0071 - val_accuracy: 0.9981\nEpoch 42/100\n200/200 [==============================] - 197s 985ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0052 - val_accuracy: 0.9981\nEpoch 43/100\n200/200 [==============================] - 197s 983ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.0029 - val_accuracy: 0.9994\nEpoch 44/100\n200/200 [==============================] - 197s 983ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9994\nEpoch 45/100\n200/200 [==============================] - 197s 984ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0027 - val_accuracy: 0.9987\nEpoch 46/100\n200/200 [==============================] - 195s 974ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0039 - val_accuracy: 0.9987\nEpoch 47/100\n200/200 [==============================] - 196s 981ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0025 - val_accuracy: 0.9994\nEpoch 48/100\n200/200 [==============================] - 197s 987ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.0081 - val_accuracy: 0.9975\nEpoch 49/100\n200/200 [==============================] - 196s 980ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0042 - val_accuracy: 0.9987\nEpoch 50/100\n200/200 [==============================] - 197s 982ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9994\nEpoch 51/100\n200/200 [==============================] - 197s 986ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0041 - val_accuracy: 0.9981\nEpoch 52/100\n200/200 [==============================] - 196s 982ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.0018 - val_accuracy: 0.9994\nEpoch 53/100\n200/200 [==============================] - 197s 985ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0026 - val_accuracy: 0.9994\nEpoch 54/100\n200/200 [==============================] - 194s 967ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0023 - val_accuracy: 0.9994\nEpoch 55/100\n200/200 [==============================] - 197s 986ms/step - loss: 0.0071 - accuracy: 0.9970 - val_loss: 0.0050 - val_accuracy: 0.9975\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f0772308510>"},"metadata":{}}]},{"cell_type":"code","source":"classes = np.array(list(train_full_generator.class_indices.keys()))","metadata":{"execution":{"iopub.status.busy":"2023-01-17T03:09:37.256615Z","iopub.execute_input":"2023-01-17T03:09:37.257024Z","iopub.status.idle":"2023-01-17T03:09:37.262738Z","shell.execute_reply.started":"2023-01-17T03:09:37.256992Z","shell.execute_reply":"2023-01-17T03:09:37.261363Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"logits = model.predict(train_full_generator)\nf_x = tf.nn.softmax(logits).numpy()\n\npredictions = classes[f_x.argmax(axis=1)]\nnp.mean(df_train['label'].values == predictions)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T03:09:41.065950Z","iopub.execute_input":"2023-01-17T03:09:41.066316Z","iopub.status.idle":"2023-01-17T03:11:54.567630Z","shell.execute_reply.started":"2023-01-17T03:09:41.066284Z","shell.execute_reply":"2023-01-17T03:11:54.566596Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  \"\"\"\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"0.0"},"metadata":{}}]},{"cell_type":"code","source":"logits_val = model.predict(val_generator)\n\nf_x_val = tf.nn.softmax(logits_val).numpy()\n\npredictions_val = classes[f_x_val.argmax(axis=1)]\nnp.mean(df_test['label'].values == predictions_val)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T03:12:17.206414Z","iopub.execute_input":"2023-01-17T03:12:17.206805Z","iopub.status.idle":"2023-01-17T03:12:51.183682Z","shell.execute_reply.started":"2023-01-17T03:12:17.206772Z","shell.execute_reply":"2023-01-17T03:12:51.182675Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"0.17647058823529413"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Calculate confusion matrix\nconfusion_matrix = confusion_matrix(df_test['label'].values, predictions_val, labels=list(classes))\n\n# Iterate over classes\nfor i, c in enumerate(classes):\n    # Get number of correct and incorrect classifications for each class\n    tp = confusion_matrix[i, i]\n    fn = confusion_matrix[i, :].sum() - tp\n    fp = confusion_matrix[:, i].sum() - tp\n    tn = confusion_matrix.sum() - tp - fn - fp\n\n    # Create string\n    s = f\"The number of correct classifications of {c} is {tp} and the number of incorrect classifications is {fn + fp}\"\n    print(s)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T03:12:58.211449Z","iopub.execute_input":"2023-01-17T03:12:58.211833Z","iopub.status.idle":"2023-01-17T03:12:58.224456Z","shell.execute_reply.started":"2023-01-17T03:12:58.211800Z","shell.execute_reply":"2023-01-17T03:12:58.223347Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"The number of correct classifications of cup is 77 and the number of incorrect classifications is 500\nThe number of correct classifications of fork is 11 and the number of incorrect classifications is 288\nThe number of correct classifications of glass is 27 and the number of incorrect classifications is 352\nThe number of correct classifications of knife is 42 and the number of incorrect classifications is 459\nThe number of correct classifications of plate is 67 and the number of incorrect classifications is 544\nThe number of correct classifications of spoon is 58 and the number of incorrect classifications is 489\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Create predictions based on your model","metadata":{}},{"cell_type":"code","source":"files = glob.glob(\"/kaggle/working/kitchenware_v5_*_*.h5\")\n#files = glob.glob(\"kitchenware_v4_*_*.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-01-17T03:13:08.713366Z","iopub.execute_input":"2023-01-17T03:13:08.713750Z","iopub.status.idle":"2023-01-17T03:13:08.721551Z","shell.execute_reply.started":"2023-01-17T03:13:08.713717Z","shell.execute_reply":"2023-01-17T03:13:08.720644Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"predictions = [float(re.search(\"_([0-9]+\\.[0-9]+)\\.h5\", file).group(1)) for file in files]\n\nbest_file = files[predictions.index(max(predictions))]\n\nprint(best_file)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T03:13:11.104996Z","iopub.execute_input":"2023-01-17T03:13:11.105361Z","iopub.status.idle":"2023-01-17T03:13:11.112063Z","shell.execute_reply.started":"2023-01-17T03:13:11.105329Z","shell.execute_reply":"2023-01-17T03:13:11.111049Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"/kaggle/working/kitchenware_v5_39_0.999.h5\n","output_type":"stream"}]},{"cell_type":"code","source":"model_test = keras.models.load_model(best_file)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T02:36:14.482613Z","iopub.execute_input":"2023-01-16T02:36:14.483540Z","iopub.status.idle":"2023-01-16T02:36:15.759554Z","shell.execute_reply.started":"2023-01-16T02:36:14.483506Z","shell.execute_reply":"2023-01-16T02:36:15.758660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('../input/kitchenware-classification/test.csv', dtype={'Id': str})\ndf_test['filename'] = '../input/kitchenware-classification/images/' + df_test['Id'] + '.jpg'","metadata":{"execution":{"iopub.status.busy":"2023-01-16T02:37:38.185297Z","iopub.execute_input":"2023-01-16T02:37:38.185710Z","iopub.status.idle":"2023-01-16T02:37:38.207663Z","shell.execute_reply.started":"2023-01-16T02:37:38.185672Z","shell.execute_reply":"2023-01-16T02:37:38.206762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing dataset\n\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    df_test,\n    x_col='filename',\n    class_mode='input',\n    target_size=(250, 250),\n    batch_size=32,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T02:37:56.557997Z","iopub.execute_input":"2023-01-16T02:37:56.558357Z","iopub.status.idle":"2023-01-16T02:38:09.536077Z","shell.execute_reply.started":"2023-01-16T02:37:56.558325Z","shell.execute_reply":"2023-01-16T02:38:09.534979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = np.array(list(train_full_generator.class_indices.keys()))","metadata":{"execution":{"iopub.status.busy":"2023-01-16T02:40:32.217607Z","iopub.execute_input":"2023-01-16T02:40:32.217998Z","iopub.status.idle":"2023-01-16T02:40:32.225813Z","shell.execute_reply.started":"2023-01-16T02:40:32.217966Z","shell.execute_reply":"2023-01-16T02:40:32.224694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits_test = model.predict(test_generator)\n\nf_x_test = tf.nn.softmax(logits_test).numpy()\n\npredictions_test = classes[f_x_test.argmax(axis=1)]\n","metadata":{"execution":{"iopub.status.busy":"2023-01-16T02:40:54.430114Z","iopub.execute_input":"2023-01-16T02:40:54.430475Z","iopub.status.idle":"2023-01-16T02:42:19.373121Z","shell.execute_reply.started":"2023-01-16T02:40:54.430443Z","shell.execute_reply":"2023-01-16T02:42:19.372141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_pred = model_test.predict(test_generator)\n\n#predictions = classes[y_pred.argmax(axis=1)]\n\ndf_submission = pd.DataFrame()\ndf_submission['filename'] = test_generator.filenames\ndf_submission['label'] = predictions_test\n\ndf_submission['Id'] = df_submission.filename.str[len('../input/kitchenware-classification/images/'):-4]\ndel df_submission['filename']\ndf_submission[['Id', 'label']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-16T02:43:00.824458Z","iopub.execute_input":"2023-01-16T02:43:00.824842Z","iopub.status.idle":"2023-01-16T02:43:00.850185Z","shell.execute_reply.started":"2023-01-16T02:43:00.824810Z","shell.execute_reply":"2023-01-16T02:43:00.849286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission","metadata":{"execution":{"iopub.status.busy":"2023-01-16T02:43:08.753673Z","iopub.execute_input":"2023-01-16T02:43:08.754046Z","iopub.status.idle":"2023-01-16T02:43:08.775619Z","shell.execute_reply.started":"2023-01-16T02:43:08.754015Z","shell.execute_reply":"2023-01-16T02:43:08.774619Z"},"trusted":true},"execution_count":null,"outputs":[]}]}